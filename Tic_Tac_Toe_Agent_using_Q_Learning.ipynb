{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+qgcVnhQLQyaG5SRw5kb7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayandeep27/Reinforcement-Learning/blob/main/Tic_Tac_Toe_Agent_using_Q_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6gn50IsuwVEB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tic-Tac-Toe game class\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((3, 3))  # 3x3 board, 0 represents empty\n",
        "        self.current_player = 1  # Player 1 starts\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((3, 3))\n",
        "        self.current_player = 1\n",
        "\n",
        "    def get_state(self):\n",
        "        return tuple(map(tuple, self.board))\n",
        "\n",
        "    def is_valid_move(self, move):\n",
        "        row, col = move\n",
        "        return self.board[row, col] == 0  # Check if the position is empty\n",
        "\n",
        "    def make_move(self, move):\n",
        "        if not self.is_valid_move(move):\n",
        "            return False  # Invalid move\n",
        "\n",
        "        row, col = move\n",
        "        self.board[row, col] = self.current_player\n",
        "        self.current_player = -self.current_player  # Switch player\n",
        "        return True  # Valid move\n",
        "\n",
        "    def is_winner(self, player):\n",
        "        # Check rows, columns, and diagonals for win\n",
        "        for i in range(3):\n",
        "            if all(self.board[i, :] == player) or all(self.board[:, i] == player):\n",
        "                return True\n",
        "        if all(np.diag(self.board) == player) or all(np.diag(np.fliplr(self.board)) == player):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def is_draw(self):\n",
        "        return np.all(self.board != 0) and not self.is_winner(1) and not self.is_winner(-1)\n",
        "\n",
        "    def game_over(self):\n",
        "        return self.is_winner(1) or self.is_winner(-1) or self.is_draw()\n",
        "\n",
        "    def available_moves(self):\n",
        "        return list(zip(*np.where(self.board == 0)))"
      ],
      "metadata": {
        "id": "e3pUR9BdwWYG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-learning agent class\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration-exploitation trade-off\n",
        "        self.q_table = {}  # Q-table dictionary\n",
        "\n",
        "    def get_q_value(self, state, action):\n",
        "        if state not in self.q_table:\n",
        "            self.q_table[state] = np.zeros((3, 3))\n",
        "        return self.q_table[state][action]\n",
        "\n",
        "    def choose_action(self, state, available_moves):\n",
        "        if np.random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(available_moves)  # Exploration: choose random move\n",
        "        else:\n",
        "            q_values = self.q_table.get(state, np.zeros((3, 3)))\n",
        "            best_moves = [move for move in available_moves if q_values[move] == np.max(q_values[available_moves])]\n",
        "            return random.choice(best_moves)  # Exploitation: choose move with highest Q-value\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state):\n",
        "        if state not in self.q_table:\n",
        "            self.q_table[state] = np.zeros((3, 3))\n",
        "        if next_state not in self.q_table:\n",
        "            self.q_table[next_state] = np.zeros((3, 3))\n",
        "        old_value = self.q_table[state][action]\n",
        "        next_max = np.max(self.q_table[next_state])\n",
        "        new_value = (1 - self.alpha) * old_value + self.alpha * (reward + self.gamma * next_max)\n",
        "        self.q_table[state][action] = new_value"
      ],
      "metadata": {
        "id": "JDUutTjPw5uv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to play Tic-Tac-Toe game\n",
        "def play_game(agent, human_player_first=False):\n",
        "    game = TicTacToe()\n",
        "    current_player = 1 if human_player_first else -1\n",
        "    agent_player = -current_player\n",
        "\n",
        "    while not game.game_over():\n",
        "        if current_player == 1:  # Human player's turn\n",
        "            print(\"Current board:\")\n",
        "            print(game.board)\n",
        "            print(\"Available moves:\", game.available_moves())\n",
        "            row = int(input(\"Enter row (0-2): \"))\n",
        "            col = int(input(\"Enter column (0-2): \"))\n",
        "            move = (row, col)\n",
        "            while move not in game.available_moves():\n",
        "                print(\"Invalid move. Please choose from available moves.\")\n",
        "                row = int(input(\"Enter row (0-2): \"))\n",
        "                col = int(input(\"Enter column (0-2): \"))\n",
        "                move = (row, col)\n",
        "        else:  # Agent's turn\n",
        "            state = game.get_state()\n",
        "            available_moves = game.available_moves()\n",
        "            action = agent.choose_action(state, available_moves)\n",
        "            move = action\n",
        "\n",
        "        game.make_move(move)\n",
        "        next_state = game.get_state()\n",
        "\n",
        "        if game.is_winner(agent_player):\n",
        "            print(\"Agent wins!\")\n",
        "            reward = 1\n",
        "        elif game.is_winner(-agent_player):\n",
        "            print(\"Human wins!\")\n",
        "            reward = -1\n",
        "        else:\n",
        "            print(\"It's a draw!\")\n",
        "            reward = 0\n",
        "\n",
        "        agent.update_q_table(state, move, reward, next_state)\n",
        "        current_player = -current_player  # Switch player\n",
        "\n",
        "    print(\"Final board:\")\n",
        "    print(game.board)"
      ],
      "metadata": {
        "id": "mymw7LpSxFOH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "def main():\n",
        "    agent = QLearningAgent()\n",
        "\n",
        "    episodes = 10000\n",
        "    print_every = 1000\n",
        "\n",
        "    for episode in range(1, episodes + 1):\n",
        "        agent.epsilon = 0.1 + 0.9 * (episodes - episode) / episodes  # Decreasing epsilon\n",
        "        play_game(agent)\n",
        "\n",
        "        if episode % print_every == 0:\n",
        "            print(f\"Episode {episode}/{episodes} completed.\")\n",
        "\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "    # Test against human player\n",
        "    while True:\n",
        "        play_game(agent, human_player_first=True)\n",
        "        again = input(\"Play again? (y/n): \")\n",
        "        if again.lower() != 'y':\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP9cmZ_9x5PZ",
        "outputId": "b68ec855-c667-446f-bc7a-0d3044a3df50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's a draw!\n",
            "Current board:\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "Available moves: [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 1), (2, 2)]\n",
            "Enter row (0-2): 1\n",
            "Enter column (0-2): 2\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Current board:\n",
            "[[ 1.  0.  0.]\n",
            " [ 0.  0. -1.]\n",
            " [ 1.  0.  0.]]\n",
            "Available moves: [(0, 1), (0, 2), (1, 0), (1, 1), (2, 1), (2, 2)]\n",
            "Enter row (0-2): 0\n",
            "Enter column (0-2): 0\n",
            "Invalid move. Please choose from available moves.\n",
            "Enter row (0-2): 1\n",
            "Enter column (0-2): 1\n",
            "It's a draw!\n",
            "It's a draw!\n",
            "Current board:\n",
            "[[ 1.  0.  1.]\n",
            " [ 0. -1. -1.]\n",
            " [ 1.  0.  0.]]\n",
            "Available moves: [(0, 1), (1, 0), (2, 1), (2, 2)]\n",
            "Enter row (0-2): 2\n",
            "Enter column (0-2): 1\n",
            "It's a draw!\n",
            "Agent wins!\n",
            "Final board:\n",
            "[[ 1.  1.  1.]\n",
            " [ 0. -1. -1.]\n",
            " [ 1. -1.  0.]]\n",
            "It's a draw!\n",
            "Current board:\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 0.]]\n",
            "Available moves: [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (2, 0), (2, 1), (2, 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehe5btNGx8WV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}